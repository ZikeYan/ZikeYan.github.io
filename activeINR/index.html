<!DOCTYPE html>
<html lang="en">

<script src="bootstrap.js"></script>
<script type="text/javascript" charset="utf-8" src="https://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js"></script> 
<!---
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
--->
<script src="load-mathjax.js" async></script>


<style type="text/css">
body {
    font-family: "Titillium Web", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight: 300;
    font-size: 17px;
    margin-left: auto;
    margin-right: auto;
}

@media screen and (min-width: 980px){
    body {
        width: 980px;
    }
}


h1 {
    font-weight:300;
    line-height: 1.15em;
}

h2 {
    font-size: 1.75em;
}
a:link,a:visited {
    color: #5364cc;
    text-decoration: none;
}
a:hover {
    color: #208799;
}
h1 {
    text-align: center;
}
h2,h3 {
    text-align: left;
}

h1 {
    font-size: 40px;
    font-weight: 500;
}
h2 {
    font-weight: 400;
    margin: 16px 0px 4px 0px;
}
h3 {
    font-weight: 600;
    margin: 16px 0px 4px 0px;
}

.paper-title {
    padding: 1px 0px 1px 0px;
}
section {
    margin: 32px 0px 32px 0px;
    text-align: justify;
    clear: both;
}
.col-5 {
     width: 20%;
     float: left;
}

.move-down {
    margin-top:0.6cm;
}

.col-4 {
     width: 25%;
     float: left;
}
.col-3 {
     width: 33%;
     float: left;
}
.col-2 {
     width: 50%;
     float: left;
}
.col-1 {
     width: 100%;
     float: left;
}

.col-8{
width: 12.5%;
}

.author-row, .affil-row {
    font-size: 26px;
}

.author-row-new { 
    text-align: center; 
}

.author-row-new a {
    display: inline-block;
    font-size: 20px;
    padding: 4px;
}

.author-row-new sup {
    color: #313436;
    font-size: 12px;
}

.affiliations-new {
    font-size: 18px;
    text-align: center;
    width: 80%;
    margin: 0 auto;
    margin-bottom: 20px;
}

.row {
    margin: 16px 0px 16px 0px;
}
.authors {
    font-size: 26px;
}
.affiliatons {
    font-size: 18px;
}
.affil-row {
    margin-top: 18px;
}
.teaser {
    max-width: 100%;
}
.text-center {
    text-align: center;  
}
.screenshot {
    width: 256px;
    border: 1px solid #ddd;
}
.screenshot-el {
    margin-bottom: 16px;
}
hr {
    height: 1px;
    border: 0; 
    border-top: 1px solid #ddd;
    margin: 0;
}
.material-icons {
    vertical-align: -6px;
}
p {
    line-height: 1.25em;
}
.caption {
    font-size: 16px;
    color: #666;
    margin-top: 4px;
    margin-bottom: 10px;
	text-align: left;
}


video {
    display: block;
    margin: auto;
}


figure {
    display: block;
    margin: auto;
    margin-top: 10px;
    margin-bottom: 10px;
}
#bibtex pre {
    font-size: 14px;
    background-color: #eee;
    padding: 16px;
}
.blue {
    color: #2c82c9;
    font-weight: bold;
}
.orange {
    color: #d35400;
    font-weight: bold;
}
.flex-row {
    display: flex;
    flex-flow: row wrap;
    padding: 0;
    margin: 0;
    list-style: none;
}

.paper-btn-coming-soon {
    position: relative; 
    top: 0;
    left: 0;
}

.coming-soon {
    position: absolute;
    top: -15px;
    right: -15px;
}

.center {
  margin-left: 10.0%;
  margin-right: 10.0%;
}

.paper-btn {
  position: relative;
  text-align: center;

  display: inline-block;
  margin: 8px;
  padding: 8px 8px;

  border-width: 0;
  outline: none;
  border-radius: 2px;
  
  background-color: #5364cc;
  color: white !important;
  font-size: 20px;
  width: 150px;
  font-weight: 600;
}
.paper-btn-parent {
    display: flex;
    justify-content: center;
    margin: 16px 0px;
}

.paper-btn:hover {
    opacity: 0.85;
}

.container {
    margin-left: auto;
    margin-right: auto;
    padding-left: 16px;
    padding-right: 16px;
}

.venue {
    font-size: 23px;
}

.topnav {
    background-color: #EEEEEE;
    overflow: hidden;
}

.topnav div {
    max-width: 1070px;
    margin: 0 auto;
}

.topnav a {
    display: inline-block;
    color: black;
    text-align: center;
    vertical-align: middle;
    padding: 16px 16px;
    text-decoration: none;
    font-size: 18px;
}

.topnav img {
    padding: 2px 0px;
    width: 100%;
    margin: 0.2em 0px 0.3em 0px;
    vertical-align: middle;
}

pre {
    font-size: 0.9em;
    padding-left: 7px;
    padding-right: 7px;
    padding-top: 3px;
    padding-bottom: 3px;
    border-radius: 3px;
    background-color: rgb(235, 235, 235);
    overflow-x: auto;
}

.download-thumb {
    display: flex;
}

@media only screen and (max-width: 620px) {
    .download-thumb {
        display: none;
    }
}

.paper-stuff {
    width: 50%;
    font-size: 20px;
}

@media only screen and (max-width: 620px) {
    .paper-stuff {
        width: 100%;
    }
}
* {
  box-sizing: border-box;
}

.column {
  text-align: center;
  float: left;
  width: 16.666%;
  padding: 5px;
}
.column3 {
  text-align: center;
  float: left;
  width: 33.333%;
  padding: 5px;
}
.column4 {
  text-align: center;
  float: left;
  width: 50%;
  padding: 5px;
}
.column5 {
  text-align: center;
  float: left;
  width: 20%;
  padding: 5px;
}
.column10 {
  text-align: center;
  float: left;
  width: 10%;
  padding: 5px;
}
.border-right {
    border-right: 1px solid black;
}
.border-bottom{
    border-bottom: 1px solid black;
}


.row-center {
    margin: 16px 0px 16px 0px;
    text-align: center;
}

/* Clearfix (clear floats) */
.row::after {
  content: "";
  clear: both;
  display: table;
}
.img-fluid {
  max-width: 100%;
  height: auto;
}
.figure-img {
  margin-bottom: 0.5rem;
  line-height: 1;
}








.rounded-circle {
  border-radius: 50% !important;
}






/* Responsive layout - makes the three columns stack on top of each other instead of next to each other */
@media screen and (max-width: 500px) {
  .column {
    width: 100%;
  }
}
@media screen and (max-width: 500px) {
  .column3 {
    width: 100%;
  }
}

</style>
<link rel="stylesheet" href="bootstrap-grid.css">
<link rel="stylesheet" href="simplegrid.css">

<script type="text/javascript" src="../js/hidebib.js"></script>
    <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
    <head>
        <title> Active Neural Mapping</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta property="og:description" content="Active Neural Mapping"/>
        <link href="https://fonts.googleapis.com/css2?family=Material+Icons" rel="stylesheet">
        <meta name="twitter:card" content="summary_large_image">
        <meta name="twitter:creator" content="@zike_Yan">
        <meta name="twitter:title" content="Active Neural Mapping">
        <meta name="twitter:description" content="">
        <meta name="twitter:image" content="">
    </head>

<body>

<div class="container">
    <div class="paper-title">
    <h1> 
        Active Neural Mapping
    </div>

    <div id="authors">
        <center>
            <div class="author-row-new">
                <a href="https://zikeyan.github.io//" target="_blank">Zike Yan<sup>1,2</sup></a>,
                Haoxiang Yang<sup>1,2</sup>,
                Hongbin Zha<sup>1,2</sup>
            </div>
        </center>
        <center>
        <div class="affiliations">
            <span><sup>1</sup> Key Laboratory of Machine Perception (MOE), SIST, Peking University</span> <br>
            <span><sup>2</sup> PKU-SenseTime Machine Vision Joint Lab</span>
        </div>

        <div class="affil-row">
            <div class="venue text-center"><b>ICCV 2023 </b></div>
        </div>

        </center>

        <div style="clear: both">
            <div class="paper-btn-parent">
            <a class="paper-btn" href="#" target="_blank">
                <span class="material-icons"> description </span> 
                 Paper
            </a>
            <a class="paper-btn" href="#" target="_blank">
                <span class="material-icons"> movie </span>
            	Video
       		</a>
            <a class="paper-btn" href="#"  target="_blank">
                <span class="material-icons"> code </span> 
                 Code
            </a>
			<a class="paper-btn" href="./poster.pdf"  target="_blank">
                <span class="material-icons"> photo </span> 
                 Poster
            </a>
            </div>
        </div>
    </div>

    <section id="teaser-image">
        <center>
            <figure>
                <video class="centered" width="80%" autoplay loop muted playsinline class="video-background " >
                    <source src="img/teaser.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
            </figure>

        </center>
    </section>

    <section id="abstract"/>
        <hr>
        <h2>Abstract</h2>
        <div class="flex-row">
            <p>
             We address the problem of active mapping with a continually-learned neural scene representation, namely <b>Active Neural Mapping</b>. The key lies in actively finding the target space to be explored with efficient agent movement, thus minimizing the map uncertainty on-the-fly within a previously unseen environment. In this paper, we examine the weight space of the continually-learned neural field, and show empirically that the neural variability, the prediction robustness against random weight perturbation, can be directly utilized to measure the instant uncertainty of the neural map. Together with the continuous geometric information inherited in the neural map, the agent can be guided to find a traversable path to gradually gain knowledge of the environment. We present for the first time an online active mapping system with a coordinate-based implicit neural representation. Experiments in the visually-realistic Gibson and Matterport3D environment demonstrate the efficacy of the proposed method.
            </p>
        </div>
    </section>


    <div class="section">
        <h2>Problem Formulation</h2>
        <hr>
        <p>
            We aim to best represent a scene through a neural network <b>&theta;</b>. In a batch-training paradigm, the parameters can be optimized through empirical risk minimization (ERM) given abundant training samples as:
        </p>
		<img src="img/equation/ERM.svg" style="height:100%; margin-right:-20px; margin-top:-10px;">
		<p>
			However, when deployed in an unknown environment in an online setting, the overarching goal of the optimal scene representation turns to a cumulative loss minimization (<a href="https://openreview.net/forum?id=u1XV9BPAB9" target="_blank">Raghavan and Balaprakash</a>):
		</p>
		<img src="img/equation/cumulative.svg" style="height:100%; margin-right:-20px; margin-top:-10px;">
		<p>
			 According to <a href="https://openreview.net/forum?id=u1XV9BPAB9" target="_blank">Raghavan and Balaprakash</a>, an equilibrium point can be achieved by alternatively maximizing the generalization and minimizing the forgetting of H(&delta;<b>z</b>,<b>&theta;</b><sup>t</sup>) through gradient descent-ascent strategy. This manner lays the theoretic foundation for us to solve the active mapping problem by iteratively capturing the observation &delta;<b>z</b> with most distribution shift and updating the map parameters <b>&theta;</b><sup>t</sup> continually.
		</p>
    </div>

    <div class="section">
        <h2>Solution</h2>
        <hr>
        <p>
            The minimization of H(&delta;<b>z</b>,<b>&theta;</b><sup>t</sup>) motivates us to understand the behavior of the loss L(<b>&theta;</b>, <b>z</b>) given different observation <b>z</b> and network parameters <b>&theta;</b>. We can observe evidently-different geometries for the true surface point and the false-positive one: the loss of the true surface point will be constrained in a low-loss basin, while the loss of the false-positive one stays along an unstable sharp ridge.
        </p>
		<div class="col justify-content-center text-center">
			<div class="col text-center">
				<img src="img/land_true.png" style="width:45%;">
				<img src="img/land_false.png" style="width:45%;">
			</div>
		</div>
		<p>
			The observation with most distribution shift can then be found given functionality changes against weight perturbation as:
		</p>
		<img src="img/equation/perturb.svg" style="height:100%; margin-right:-20px; margin-top:-10px;">
		<p>
			The optimization is iteratively conducted along with the target location (next-best-view) identification. A <a href="https://wijmans.xyz/publication/ddppo-2019/" target="_blank">DD-PPO</a> is deployed as a planner that drives the agent towards the target location, while an implicit neural representation is updated on-the-fly (Similar to <a href="https://edgarsucar.github.io/iMAP/" target="_blank">iMAP</a>, <a href="../continualINR/index.html" target="_blank">Continual Neural Mapping</a>, and <a href="https://joeaortiz.github.io/iSDF/" target="_blank">iSDF</a>) to minimize forgetting given new observations.  
		</p>
		<div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <video width="80%" playsinline="" autoplay="" loop="" preload="" muted="">
                    <source src="img/optimization.mp4" type="video/mp4">
                </video>
            </div> 
        </div>
    </div>

    <div class="section">
        <h2>More Results</h2>
        <hr>
        <p>
            Next, we provide baseline comparisons of our approach with IBRNet, pixelNeRF, GPNR on different outdoor scenes in ACID.
        </p>
        <div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <video width="75%" playsinline="" autoplay="" loop="" preload="" muted="">
                    <source src="img/results.mp4" type="video/mp4">
                </video>
            </div> 
        </div>
    </div>
	<br>
    <div class="section">
        <h2>Paper</h2>
        <hr>
        <p>
        </p>
        <div>
            <div class="list-group">
                <a href="" target="_blank"
                   class="list-group-item">
                    <img src="img/thumbnail_iccv_2023.jpg" style="width:100%; margin-right:-20px; margin-top:-10px;">
                </a>
            </div>
        </div>
    </div>

        <div class="section">
            <h2>Our Related Projects</h2>
            <hr>


            <div class='row vspace-top'>
                <div class="col-sm-3">
                    <div class="move-down">
                        <img src='img/continualINR.png' class='img-fluid'>
                    </div>
                </div>

                <div class="col">
                    <div class='paper-title'>
                        <a href="../continualINR/index.html" target="_blank">Continual Neural Mapping</a> , ICCV 2021
                    </div>
                    <div>
                        We present a method to capture a dynamic scene utilizing a spatial-temporal radiance field. We enforce consistency in this field utilizing a continuous flow field. We show that such an approach enables us to synthesize novel views in dynamic scenes captured using as little as a single monocular video, and further show that our radiance field can be utilized to denoise and super-resolve input images.
                    </div>
                </div>
            </div>

    <hr>

    <section id="bibtex">
        <h2>Citation</h2>
        <hr>
        <pre><code>@inproceedings{Yan2023iccv,
                  title={Active Neural Mapping},
                  author={Yan, Zike and Yang, Haoxiang and Zha, Hongbin},
                  booktitle={Intl. Conf. on Computer Vision (ICCV)},
                  year={2023}
                }</code></pre>
    </section>

    <section>
        This webpage template was recycled from <a href='https://yilundu.github.io/wide_baseline/' target="_blank">here</a>.
    </section>

</div>

</body>
</html>