<!DOCTYPE html>
<html lang="en">

<script src="bootstrap.js"></script>
<script type="text/javascript" charset="utf-8" src="https://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js"></script> 
<!---
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
--->
<script src="load-mathjax.js" async></script>


<style type="text/css">
body {
    font-family: "Titillium Web", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight: 300;
    font-size: 17px;
    margin-left: auto;
    margin-right: auto;
}

@media screen and (min-width: 980px){
    body {
        width: 980px;
    }
}


h1 {
    font-weight:300;
    line-height: 1.15em;
}

h2 {
    font-size: 1.75em;
}
a:link,a:visited {
    color: #5364cc;
    text-decoration: none;
}
a:hover {
    color: #208799;
}
h1 {
    text-align: center;
}
h2,h3 {
    text-align: left;
}

h1 {
    font-size: 40px;
    font-weight: 500;
}
h2 {
    font-weight: 400;
    margin: 16px 0px 4px 0px;
}
h3 {
    font-weight: 600;
    margin: 16px 0px 4px 0px;
}

.paper-title {
    padding: 1px 0px 1px 0px;
}
section {
    margin: 32px 0px 32px 0px;
    text-align: justify;
    clear: both;
}
.col-5 {
     width: 20%;
     float: left;
}

.move-down {
    margin-top:0.6cm;
}

.col-4 {
     width: 25%;
     float: left;
}
.col-3 {
     width: 33%;
     float: left;
}
.col-2 {
     width: 50%;
     float: left;
}
.col-1 {
     width: 100%;
     float: left;
}

.col-8{
width: 12.5%;
}

.author-row, .affil-row {
    font-size: 26px;
}

.author-row-new { 
    text-align: center; 
}

.author-row-new a {
    display: inline-block;
    font-size: 20px;
    padding: 4px;
}

.author-row-new sup {
    color: #313436;
    font-size: 12px;
}

.affiliations-new {
    font-size: 18px;
    text-align: center;
    width: 80%;
    margin: 0 auto;
    margin-bottom: 20px;
}

.row {
    margin: 16px 0px 16px 0px;
}
.authors {
    font-size: 26px;
}
.affiliatons {
    font-size: 18px;
}
.affil-row {
    margin-top: 18px;
}
.teaser {
    max-width: 100%;
}
.text-center {
    text-align: center;  
}
.screenshot {
    width: 256px;
    border: 1px solid #ddd;
}
.screenshot-el {
    margin-bottom: 16px;
}
hr {
    height: 1px;
    border: 0; 
    border-top: 1px solid #ddd;
    margin: 0;
}
.material-icons {
    vertical-align: -6px;
}
p {
    line-height: 1.25em;
}
.caption {
    font-size: 16px;
    color: #666;
    margin-top: 4px;
    margin-bottom: 10px;
	text-align: left;
}


video {
    display: block;
    margin: auto;
}


figure {
    display: block;
    margin: auto;
    margin-top: 10px;
    margin-bottom: 10px;
}
#bibtex pre {
    font-size: 14px;
    background-color: #eee;
    padding: 16px;
}
.blue {
    color: #2c82c9;
    font-weight: bold;
}
.orange {
    color: #d35400;
    font-weight: bold;
}
.flex-row {
    display: flex;
    flex-flow: row wrap;
    padding: 0;
    margin: 0;
    list-style: none;
}

.paper-btn-coming-soon {
    position: relative; 
    top: 0;
    left: 0;
}

.coming-soon {
    position: absolute;
    top: -15px;
    right: -15px;
}

.center {
  margin-left: 10.0%;
  margin-right: 10.0%;
}

.paper-btn {
  position: relative;
  text-align: center;

  display: inline-block;
  margin: 8px;
  padding: 8px 8px;

  border-width: 0;
  outline: none;
  border-radius: 2px;
  
  background-color: #5364cc;
  color: white !important;
  font-size: 20px;
  width: 150px;
  font-weight: 600;
}
.paper-btn-parent {
    display: flex;
    justify-content: center;
    margin: 16px 0px;
}

.paper-btn:hover {
    opacity: 0.85;
}

.container {
    margin-left: auto;
    margin-right: auto;
    padding-left: 16px;
    padding-right: 16px;
}

.venue {
    font-size: 23px;
}

.topnav {
    background-color: #EEEEEE;
    overflow: hidden;
}

.topnav div {
    max-width: 1070px;
    margin: 0 auto;
}

.topnav a {
    display: inline-block;
    color: black;
    text-align: center;
    vertical-align: middle;
    padding: 16px 16px;
    text-decoration: none;
    font-size: 18px;
}

.topnav img {
    padding: 2px 0px;
    width: 100%;
    margin: 0.2em 0px 0.3em 0px;
    vertical-align: middle;
}

pre {
    font-size: 0.9em;
    padding-left: 7px;
    padding-right: 7px;
    padding-top: 3px;
    padding-bottom: 3px;
    border-radius: 3px;
    background-color: rgb(235, 235, 235);
    overflow-x: auto;
}

.download-thumb {
    display: flex;
}

@media only screen and (max-width: 620px) {
    .download-thumb {
        display: none;
    }
}

.paper-stuff {
    width: 50%;
    font-size: 20px;
}

@media only screen and (max-width: 620px) {
    .paper-stuff {
        width: 100%;
    }
}
* {
  box-sizing: border-box;
}

.column {
  text-align: center;
  float: left;
  width: 16.666%;
  padding: 5px;
}
.column3 {
  text-align: center;
  float: left;
  width: 33.333%;
  padding: 5px;
}
.column4 {
  text-align: center;
  float: left;
  width: 50%;
  padding: 5px;
}
.column5 {
  text-align: center;
  float: left;
  width: 20%;
  padding: 5px;
}
.column10 {
  text-align: center;
  float: left;
  width: 10%;
  padding: 5px;
}
.border-right {
    border-right: 1px solid black;
}
.border-bottom{
    border-bottom: 1px solid black;
}


.row-center {
    margin: 16px 0px 16px 0px;
    text-align: center;
}

/* Clearfix (clear floats) */
.row::after {
  content: "";
  clear: both;
  display: table;
}
.img-fluid {
  max-width: 100%;
  height: auto;
}
.figure-img {
  margin-bottom: 0.5rem;
  line-height: 1;
}








.rounded-circle {
  border-radius: 50% !important;
}






/* Responsive layout - makes the three columns stack on top of each other instead of next to each other */
@media screen and (max-width: 500px) {
  .column {
    width: 100%;
  }
}
@media screen and (max-width: 500px) {
  .column3 {
    width: 100%;
  }
}

</style>
<link rel="stylesheet" href="bootstrap-grid.css">
<link rel="stylesheet" href="simplegrid.css">

<script type="text/javascript" src="../js/hidebib.js"></script>
    <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
    <head>
        <title> Continual Neural Mapping</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta property="og:description" content="Continual Neural Mapping"/>
        <link href="https://fonts.googleapis.com/css2?family=Material+Icons" rel="stylesheet">
        <meta name="twitter:card" content="summary_large_image">
        <meta name="twitter:creator" content="@zike_Yan">
        <meta name="twitter:title" content="Continual Neural Mapping">
        <meta name="twitter:description" content="">
        <meta name="twitter:image" content="">
    </head>

<body>

<div class="container">
    <div class="paper-title">
    <h1> 
        Continual Neural Mapping: Learning an Implicit Scene Representation from Sequential Observations
    </div>

    <div id="authors">
        <center>
            <div class="author-row-new">
                <a href="https://zikeyan.github.io//" target="_blank">Zike Yan<sup>1,2</sup></a>,
                Yuxin Tian<sup>3</sup>,
				Xuesong Shi<sup>4</sup>,
				Ping Guo<sup>4</sup>,
				Peng Wang<sup>4</sup>,
                Hongbin Zha<sup>1,2</sup>
            </div>
        </center>
        <center>
        <div class="affiliations">
            <span><sup>1</sup> Key Laboratory of Machine Perception (MOE), SIST, Peking University</span><br>
            <span><sup>2</sup> PKU-SenseTime Machine Vision Joint Lab</span><br>
			<span><sup>3</sup> School of Automation Science and Electrical Engineering, Beihang University</span><br>
			<span><sup>4</sup> Intel Labs China</span>
			
        </div>

        <div class="affil-row">
            <div class="venue text-center"><b>ICCV 2021 </b></div>
        </div>

        </center>

        <div style="clear: both">
            <div class="paper-btn-parent">
            <a class="paper-btn" href="https://arxiv.org/abs/2108.05851" target="_blank">
                <span class="material-icons"> description </span>
                 Paper
            </a>
			<a class="paper-btn" href="https://youtu.be/2nCmEaWv114" target="_blank">
                <span class="material-icons"> movie </span>
            	Video
       		</a>
            <a class="paper-btn" href="#"  target="_blank">
                <span class="material-icons"> code </span> 
                 Code
            </a>
			<a class="paper-btn" href="./poster.pdf"  target="_blank">
                <span class="material-icons"> photo </span> 
                 Poster
            </a>
            </div>
        </div>
    </div>

    <section id="teaser-image">
        <center>
            <figure>
                <video class="centered" width="90%" autoplay loop muted playsinline class="video-background " >
                    <source src="img/teaser.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
            </figure>

        </center>
    </section>

    <section id="abstract"/>
        <hr>
        <h2>Abstract</h2>
        <div class="flex-row">
            <p>
            Recent advances have enabled a single neural network to serve as an implicit scene representation, establishing the mapping function between spatial coordinates and scene properties. In this paper, we make a further step towards <i>continual learning of the implicit scene representation directly from sequential observations</i>, namely <b>Continual Neural Mapping</b>. The proposed problem setting bridges the gap between batch-trained implicit neural representations and commonly used streaming data in robotics and vision communities. We introduce an experience replay approach to tackle an exemplary task of continual neural mapping: approximating a continuous signed distance function (SDF) from sequential depth images as a scene geometry representation. We show for the first time that a single network can represent scene geometry over time continually without catastrophic forgetting, while achieving promising trade-offs between accuracy and efficiency.
            </p>
        </div>
    </section>


    <div class="section">
        <h2>Problem Setting</h2>
        <hr>
        <p>
            Continual neural mapping not only alleviates the <i>catastrophic forgetting</i> caused by the constant distribution shift of sequential observations, but reduces the expensive cost of batch retraining.
        </p>
        <div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <video width="95%" playsinline="" autoplay="" loop="" preload="" muted="">
                    <source src="img/baselines.mp4" type="video/mp4">
                </video>
            </div> 
        </div>
    </div>

    <div class="section">
        <h2>Method</h2>
        <hr>
        <p>
            We adopt an experience-replay based continual learning strategy. Past experiences are leveraged to supervise both the zero-crossing surfaces and the non-surface regions. Note that off-surface samples behind the surface (red ones) may lead to false negatives. We modify the regularization terms of <a href="https://www.vincentsitzmann.com/siren/"  target="_blank">SIREN</a> to handle the non-closed geometry.
        </p>
        <div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <img src="img/experience-replay.png" style="width:45%; margin-right:20px;">
				<img src="img/sample.jpg" style="width:45%; margin-left:20px;">
            </div> 
        </div>
    </div>

    <div class="section">
        <h2>Reconstruction Results</h2>
        <hr>
        <p>
           The scene geometry is gradually updated given sequential observations, encoded by a &lt;800kB MLP compactly.
		</p>
		<figure style="margin-bottom:40px;">
                <video class="centered" width="95%" autoplay loop muted playsinline class="video-background" >
                    <source src="img/result.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
        </figure>
		<div class="col justify-content-center text-center sketchfab-embed-wrapper"> 
		  <iframe width="100%" height="400" src="https://sketchfab.com/playlists/embed?collection=db46e381f8134a0e9a8f7710ce0fe36c&autospin=1&autostart=1"
			title="Continual Neural Mapping"
			frameborder="0"
			allowfullscreen
			mozallowfullscreen="true"
			webkitallowfullscreen="true"
			allow="autoplay; fullscreen; xr-spatial-tracking"
			xr-spatial-tracking
			execution-while-out-of-viewport
			execution-while-not-rendered
			web-share
			></iframe>
		</div>
    </div>


    <div class="section">
        <h2>Open Problems</h2>
        <hr>
        <p>
           We address two critical problems to be explored under the proposed continual neural mapping setting:
		   <ul>
  				<li>
					<a href="https://scholar.google.com.hk/scholar?q=stability-plasticity+dilemma&hl=zh-CN&as_sdt=0&as_vis=1&oi=scholart" target="_blank">Stability-plasticity dilemma</a>
			    </li>
			   	The neural network is expected to adapt efficiently given new observations, while avoiding forgetting in previously-visited areas. The trade-offs between adaptation (network plasticity) and forgetting (network stability) are critical for online mapping systems such as <a href="https://edgarsucar.github.io/iMAP/" target="_blank">iMAP</a>, <a href="https://pengsongyou.github.io/nice-slam" target="_blank">NICE-SLAM</a>, <a href="https://joeaortiz.github.io/iSDF/" target="_blank">iSDF</a>.
			    <div class="row align-items-center">
            		<div class="col justify-content-center text-center">
                		<img src="img/trade-off.png" style="width:100%; margin-right:20px;">
            		</div>
        		</div>
  				<li>Uncertainty quatification</li>
			   	The continuous nature of the implicit neural representation leads to spurious zero-crossing surfaces in unseen areas, thus requiring accurate quantification of the forward prediction confidence.
		   </ul>
        </p>
    </div>

    <div class="section">
        <h2>Paper</h2>
        <hr>
        <p>
        </p>
        <div>
            <div class="list-group">
                <a href="" target="_blank"
                   class="list-group-item">
                    <img src="img/thumbnail_iccv_2021.jpg" style="width:100%; margin-right:-20px; margin-top:-10px;">
                </a>
            </div>
        </div>
    </div>

        <div class="section">
            <h2>Our Related Projects</h2>
            <hr>
            <div class='row vspace-top'>
                <div class="col-sm-3">
                    <div>
                        <img src='img/activeINR.jpg' class='img-fluid'>
                    </div>
                </div>

                <div class="col">
                    <div class='paper-title'>
                        <a href="../activeINR/index.html" target="_blank">Active Neural Mapping</a> , ICCV 2023
                    </div>
                    <div>
                        We extend the continual neural mapping method to an active mapping fashion. A mobile agent autonomously explores an indoor environment and reconstructs the scene geometry on-the-fly with an implicit neural representation.
                    </div>
                </div>
            </div>

    <hr>

    <section id="bibtex">
        <h2>Citation</h2>
        <hr>
        <pre><code>@inproceedings{Yan2021iccv,
		title={Continual Neural Mapping: Learning an Implicit Scene Representation from Sequential Observations},
		author={Yan, Zike and Tian, Yuxin and Shi, Xuesong and Guo, Ping and Wang, Peng and Zha, Hongbin},
		booktitle={Intl. Conf. on Computer Vision (ICCV)},
		pages={15782--15792},
		year={2021}
		}
		</code></pre>
    </section>

    <section>
        This webpage template was recycled from <a href='https://yilundu.github.io/wide_baseline/' target="_blank">here</a>.
    </section>

</div>

</body>
</html>
